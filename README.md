# ml-deployment-playground
Train a deep learning model on the Digits dataset and deploy it across various platforms including Flask, FastAPI, Streamlit, Docker, AWS, Heroku, TensorFlow Serving, and more.

This repository provides an end-to-end pipeline for building and deploying a deep learning model using the popular digits dataset from scikit-learn. It covers model training, evaluation, serialization, and deployment to multiple environments and platforms. Whether you're deploying locally with Flask or Streamlit, using containers via Docker, or scaling in the cloud with AWS, GCP, or Azure, this project serves as a one-stop reference for production-ready machine learning deployment workflows.

## ğŸ” Overview

This repository showcases:

- âœ… Data preparation and training using Keras (TensorFlow)
- âœ… Evaluation and serialization of the model
- âœ… REST API deployment using Flask and FastAPI
- âœ… UI-based deployment with Streamlit and Gradio
- âœ… Containerized deployment via Docker
- âœ… Cloud deployment on AWS SageMaker, Google Cloud AI, Azure ML
- âœ… Hosting via Heroku and Hugging Face Spaces
- âœ… Model serving using TensorFlow Serving and ONNX Runtime

---

## ğŸ“¦ Folder Structure

```plaintext
ml-deployment-playground/
â”‚
â”œâ”€â”€ model/                      # Trained model files
â”‚   â”œâ”€â”€ digits_model.h5
â”‚   â””â”€â”€ class_names.pkl
â”‚
â”œâ”€â”€ training/                   # Model training scripts
â”‚   â””â”€â”€ train_model.py
â”‚
â”œâ”€â”€ flask_app/                  # Flask deployment
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ streamlit_app/             # Streamlit deployment
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ fastapi_app/               # FastAPI deployment
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ docker/                    # Docker deployment files
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ gradio_app/                # Gradio interface
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ tf_serving/                # TensorFlow serving export
â”‚   â””â”€â”€ saved_model/...
â”‚
â”œâ”€â”€ onnx/                      # ONNX model export
â”‚   â””â”€â”€ model.onnx
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
